{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Escalar Variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Creacion de los modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Conexion a google drive para carga de dataset\n",
    "# ==============================================================================\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Configuración matplotlib\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#evaluacion de variables\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/media_prediction_and_its_cost.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['food_category', 'food_department', 'food_family',\n",
       "       'store_sales(in millions)', 'store_cost(in millions)',\n",
       "       'unit_sales(in millions)', 'promotion_name', 'sales_country',\n",
       "       'marital_status', 'gender', 'total_children', 'education',\n",
       "       'member_card', 'occupation', 'houseowner', 'avg_cars_at home(approx)',\n",
       "       'avg. yearly_income', 'num_children_at_home',\n",
       "       'avg_cars_at home(approx).1', 'brand_name', 'SRP', 'gross_weight',\n",
       "       'net_weight', 'recyclable_package', 'low_fat', 'units_per_case',\n",
       "       'store_type', 'store_city', 'store_state', 'store_sqft', 'grocery_sqft',\n",
       "       'frozen_sqft', 'meat_sqft', 'coffee_bar', 'video_store', 'salad_bar',\n",
       "       'prepared_food', 'florist', 'media_type', 'cost'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "df_items=df[[ 'SRP','net_weight', 'recyclable_package', 'low_fat', 'units_per_case', 'food_family',       \n",
    "       'unit_sales(in millions)', 'promotion_name', 'sales_country']]\n",
    "df_user=df[['marital_status', 'gender', 'total_children', 'education',\n",
    "       'member_card', 'occupation', 'houseowner', 'avg_cars_at home(approx)',\n",
    "       'avg. yearly_income', 'num_children_at_home']]\n",
    "df_store=df[['store_type', 'store_state' , 'grocery_sqft',\n",
    "       'frozen_sqft', 'coffee_bar', 'video_store',\n",
    "       'prepared_food', 'florist', 'media_type']]\n",
    "\n",
    "\n",
    "\n",
    "result = []\n",
    "\n",
    "for col in df_items.columns:\n",
    "    dic={}\n",
    "    unique_values = df_items[col].unique().tolist()\n",
    "    dic[col] = unique_values\n",
    "    result.append(dic)\n",
    "with open('df_items.json', 'w') as jf: \n",
    "    json.dump(result, jf, ensure_ascii=False, indent=2)\n",
    "\n",
    "result = []\n",
    "for col in df_user.columns:\n",
    "    dic={}\n",
    "    unique_values = df_user[col].unique().tolist()\n",
    "    dic[col] = unique_values\n",
    "    result.append(dic)\n",
    "with open('df_user.json', 'w') as jf: \n",
    "    json.dump(result, jf, ensure_ascii=False, indent=2)\n",
    "\n",
    "result = []\n",
    "for col in df_store.columns:\n",
    "    dic={}\n",
    "    unique_values = df_store[col].unique().tolist()\n",
    "    dic[col] = unique_values\n",
    "    result.append(dic)\n",
    "with open('df_store.json', 'w') as jf: \n",
    "    json.dump(result, jf, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "result = []\n",
    "for col in df.columns:\n",
    "    dic={}\n",
    "    unique_values = df[col].unique().tolist()\n",
    "    dic[col] = unique_values\n",
    "    result.append(dic)\n",
    "with open('df_completa.json', 'w') as jf: \n",
    "    json.dump(result, jf, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
